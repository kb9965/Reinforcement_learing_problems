{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMEElImUE371TjAoAlw8wmU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"95k9sniNy6p_"},"outputs":[],"source":["import numpy as np\n","\n","class GridWorld:\n","    def __init__(self, rows, cols, start, goal, obstacles):\n","        self.rows = rows\n","        self.cols = cols\n","        self.start = start\n","        self.goal = goal\n","        self.obstacles = obstacles\n","        self.discount_factor = 0.9\n","        self.actions = [\"up\", \"down\", \"left\", \"right\"]\n","\n","    def transitions(self, state, action):\n","        row, col = state\n","\n","        if action == \"up\":\n","            next_state = (max(row - 1, 0), col)\n","        elif action == \"down\":\n","            next_state = (min(row + 1, self.rows - 1), col)\n","        elif action == \"left\":\n","            next_state = (row, max(col - 1, 0))\n","        elif action == \"right\":\n","            next_state = (row, min(col + 1, self.cols - 1))\n","\n","        reward = 1 if next_state == self.goal else 0\n","        return [(next_state, reward, 1.0)]\n","\n","def value_iteration(grid_world, epsilon=1e-6):\n","    V = np.zeros((grid_world.rows, grid_world.cols))\n","\n","    while True:\n","        delta = 0\n","        for row in range(grid_world.rows):\n","            for col in range(grid_world.cols):\n","                if (row, col) == grid_world.goal:\n","                    continue\n","\n","                v = V[row, col]\n","                max_value = max(\n","                    sum(prob * (reward + grid_world.discount_factor * V[next_row, next_col])\n","                        for (next_row, next_col), reward, prob in grid_world.transitions((row, col), action))\n","                    for action in grid_world.actions\n","                )\n","\n","                V[row, col] = max_value\n","                delta = max(delta, abs(v - V[row, col]))\n","\n","        if delta < epsilon:\n","            break\n","\n","    return V\n","\n","def main():\n","    grid_world = GridWorld(rows=3, cols=4, start=(2, 0), goal=(0, 3), obstacles=[])\n","    optimal_value_function = value_iteration(grid_world)\n","\n","    print(\"Optimal Value Function:\")\n","    print(optimal_value_function)\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","source":["import numpy as np\n","\n","class GridWorld:\n","    def __init__(self, rows, cols, start, goal, obstacles):\n","        self.rows = rows\n","        self.cols = cols\n","        self.start = start\n","        self.goal = goal\n","        self.obstacles = obstacles\n","        self.discount_factor = 0.9\n","        self.actions = [\"up\", \"down\", \"left\", \"right\"]\n","\n","    def transitions(self, state, action):\n","        row, col = state\n","\n","        if action == \"up\":\n","            next_state = (max(row - 1, 0), col)\n","        elif action == \"down\":\n","            next_state = (min(row + 1, self.rows - 1), col)\n","        elif action == \"left\":\n","            next_state = (row, max(col - 1, 0))\n","        elif action == \"right\":\n","            next_state = (row, min(col + 1, self.cols - 1))\n","\n","        reward = 1 if next_state == self.goal else 0\n","        return [(next_state, reward, 1.0)]\n","\n","def value_iteration(grid_world, epsilon=1e-6):\n","    V = np.zeros((grid_world.rows, grid_world.cols))\n","\n","    iteration = 0  # Add an iteration counter\n","\n","    while True:\n","        delta = 0\n","        for row in range(grid_world.rows):\n","            for col in range(grid_world.cols):\n","                if (row, col) == grid_world.goal:\n","                    continue\n","\n","                v = V[row, col]\n","                max_value = max(\n","                    sum(prob * (reward + grid_world.discount_factor * V[next_row, next_col])\n","                        for (next_row, next_col), reward, prob in grid_world.transitions((row, col), action))\n","                    for action in grid_world.actions\n","                )\n","\n","                V[row, col] = max_value\n","                delta = max(delta, abs(v - V[row, col]))\n","\n","        # Print the value function for every iteration\n","        print(f\"Iteration {iteration} - Value Function:\")\n","        print(V)\n","\n","        iteration += 1\n","\n","        if delta < epsilon:\n","            break\n","\n","    return V\n","\n","def main():\n","    grid_world = GridWorld(rows=3, cols=4, start=(2, 0), goal=(0, 3), obstacles=[])\n","    optimal_value_function = value_iteration(grid_world)\n","\n","    print(\"Optimal Value Function:\")\n","    print(optimal_value_function)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zl7XYYrC6exL","executionInfo":{"status":"ok","timestamp":1707986672105,"user_tz":-330,"elapsed":578,"user":{"displayName":"KARTHIK B (RA2112701010014)","userId":"06219581223758280302"}},"outputId":"b25693f9-574a-46cb-c1f9-8012c96a1274"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0 - Value Function:\n","[[0.   0.   1.   0.  ]\n"," [0.   0.   0.9  1.  ]\n"," [0.   0.   0.81 0.9 ]]\n","Iteration 1 - Value Function:\n","[[0.    0.9   1.    0.   ]\n"," [0.    0.81  0.9   1.   ]\n"," [0.    0.729 0.81  0.9  ]]\n","Iteration 2 - Value Function:\n","[[0.81   0.9    1.     0.    ]\n"," [0.729  0.81   0.9    1.    ]\n"," [0.6561 0.729  0.81   0.9   ]]\n","Iteration 3 - Value Function:\n","[[0.81   0.9    1.     0.    ]\n"," [0.729  0.81   0.9    1.    ]\n"," [0.6561 0.729  0.81   0.9   ]]\n","Optimal Value Function:\n","[[0.81   0.9    1.     0.    ]\n"," [0.729  0.81   0.9    1.    ]\n"," [0.6561 0.729  0.81   0.9   ]]\n"]}]}]}