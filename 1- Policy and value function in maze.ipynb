{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNrAFNLsnMcfRI9R42Bzt8K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yoUVEa0fqufZ","executionInfo":{"status":"ok","timestamp":1707965586321,"user_tz":-330,"elapsed":370,"user":{"displayName":"KARTHIK B (RA2112701010014)","userId":"06219581223758280302"}},"outputId":"7589cb8f-3861-47c6-8353-c38b90d438c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Value Function:\n","[[inf inf inf]\n"," [inf inf inf]\n"," [inf inf  0.]]\n","\n","Optimal Policy:\n","[[0 0 0]\n"," [0 0 0]\n"," [0 0 0]]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-1-a12d3d41e395>:43: RuntimeWarning: overflow encountered in scalar add\n","  [sum(maze.step(action)[1] + gamma * value_function[new_row, new_col]\n","<ipython-input-1-a12d3d41e395>:49: RuntimeWarning: invalid value encountered in scalar subtract\n","  delta = max(delta, abs(new_value - old_value))\n"]}],"source":["import numpy as np\n","\n","class Maze:\n","    def __init__(self, rows, cols, start, goal, obstacles):\n","        self.rows = rows\n","        self.cols = cols\n","        self.start = start\n","        self.goal = goal\n","        self.obstacles = obstacles\n","        self.state = start\n","\n","    def reset(self):\n","        self.state = self.start\n","        return self.state\n","\n","    def step(self, action):\n","        row, col = self.state\n","        if action == \"up\" and row > 0 and (row - 1, col) not in self.obstacles:\n","            self.state = (row - 1, col)\n","        elif action == \"down\" and row < self.rows - 1 and (row + 1, col) not in self.obstacles:\n","            self.state = (row + 1, col)\n","        elif action == \"left\" and col > 0 and (row, col - 1) not in self.obstacles:\n","            self.state = (row, col - 1)\n","        elif action == \"right\" and col < self.cols - 1 and (row, col + 1) not in self.obstacles:\n","            self.state = (row, col + 1)\n","\n","        done = self.state == self.goal\n","        reward = 1 if done else 0\n","        return self.state, reward, done\n","\n","def value_iteration(maze, gamma, epsilon, max_iterations=1000):\n","    value_function = np.zeros((maze.rows, maze.cols))\n","\n","    for _ in range(max_iterations):\n","        delta = 0\n","        for row in range(maze.rows):\n","            for col in range(maze.cols):\n","                if (row, col) == maze.goal:\n","                    continue  # Value at the goal state is already 0\n","\n","                old_value = value_function[row, col]\n","                new_value = max(\n","                    [sum(maze.step(action)[1] + gamma * value_function[new_row, new_col]\n","                         for new_row, new_col in [(row-1, col), (row+1, col), (row, col-1), (row, col+1)]\n","                         if 0 <= new_row < maze.rows and 0 <= new_col < maze.cols and (new_row, new_col) not in maze.obstacles)\n","                     for action in [\"up\", \"down\", \"left\", \"right\"]])\n","\n","                value_function[row, col] = new_value\n","                delta = max(delta, abs(new_value - old_value))\n","\n","        if delta < epsilon:\n","            break\n","\n","    # Derive the optimal policy from the computed value function\n","    policy = np.zeros((maze.rows, maze.cols), dtype=int)\n","    for row in range(maze.rows):\n","        for col in range(maze.cols):\n","            if (row, col) == maze.goal:\n","                continue\n","            policy[row, col] = np.argmax(\n","                [sum(maze.step(action)[1] + gamma * value_function[new_row, new_col]\n","                     for new_row, new_col in [(row-1, col), (row+1, col), (row, col-1), (row, col+1)]\n","                     if 0 <= new_row < maze.rows and 0 <= new_col < maze.cols and (new_row, new_col) not in maze.obstacles)\n","                 for action in [\"up\", \"down\", \"left\", \"right\"]])\n","\n","    return value_function, policy\n","\n","def main():\n","    maze = Maze(rows=3, cols=3, start=(0, 0), goal=(2, 2), obstacles=[(1, 1)])\n","    gamma = 0.9\n","    epsilon = 1e-6\n","\n","    value_function, policy = value_iteration(maze, gamma, epsilon)\n","\n","    print(\"Value Function:\")\n","    print(value_function)\n","    print(\"\\nOptimal Policy:\")\n","    print(policy)\n","\n","if __name__ == \"__main__\":\n","    main()\n",""]}]}