{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP85z/6+QczJBeNelEuF5/t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import random\n","\n","# Define a 4x4 Gridworld\n","class Gridworld:\n","    def __init__(self):\n","        self.rows = 4\n","        self.cols = 4\n","        self.n_states = self.rows * self.cols\n","        self.n_actions = 4  # up, down, left, right\n","        self.actions = ['up', 'down', 'left', 'right']\n","        self.state2idx = {(r, c): r*self.cols + c for r in range(self.rows) for c in range(self.cols)}\n","        self.idx2state = {idx: state for state, idx in self.state2idx.items()}\n","        self.terminal_state = (4, 4)\n","        self.rewards = {(r, c): -1 for r in range(self.rows) for c in range(self.cols) if (r, c) != self.terminal_state}\n","        self.rewards[self.terminal_state] = 0\n","        self.transition_probs = self._compute_transition_probs()\n","\n","    def _compute_transition_probs(self):\n","        transition_probs = {}\n","        for state, idx in self.state2idx.items():\n","            for action in self.actions:\n","                transition_probs[(state, action)] = self.get_transition_prob(state, action)\n","        return transition_probs\n","\n","    def get_transition_prob(self, state, action):\n","        if state == self.terminal_state:\n","            return [(1.0, state)]\n","\n","        next_state = self._get_next_state(state, action)\n","        return [(1.0, next_state)]\n","\n","    def _get_next_state(self, state, action):\n","        row, col = state\n","        if action == 'up':\n","            row = max(0, row - 1)\n","        elif action == 'down':\n","            row = min(self.rows - 1, row + 1)\n","        elif action == 'left':\n","            col = max(0, col - 1)\n","        elif action == 'right':\n","            col = min(self.cols - 1, col + 1)\n","        return (row, col)\n","\n","\n","def random_policy(env):\n","    # Define a random policy where each action is chosen with equal probability\n","    return {state: random.choice(env.actions) for state in env.state2idx.keys() if state != env.terminal_state}\n","\n","def policy_evaluation(env, policy, gamma=1, theta=1e-6, max_iterations=100):\n","    # Initialize value function to zeros\n","    V = np.zeros(env.n_states)\n","\n","    for _ in range(max_iterations):\n","        prev_V = V.copy()\n","        for state, idx in env.state2idx.items():\n","            if state == env.terminal_state:\n","                continue\n","            v = V[idx]\n","            action = policy[state]\n","            transition_probs = env.transition_probs[(state, action)]\n","            new_v = sum(prob * (env.rewards[next_state] + gamma * V[env.state2idx[next_state]]) for prob, next_state in transition_probs)\n","            V[idx] = new_v\n","        if np.max(np.abs(prev_V - V)) < theta:\n","            break\n","    return V\n","\n","# Create 4x4 Gridworld\n","env = Gridworld()\n","\n","# Define random policy\n","policy = random_policy(env)\n","\n","# Perform policy evaluation\n","V = policy_evaluation(env, policy)\n","\n","# Reshape the value function to match the grid shape\n","V_grid = np.reshape(V, (env.rows, env.cols))\n","print(V_grid)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_zrGzw59mXu","executionInfo":{"status":"ok","timestamp":1709178282165,"user_tz":-330,"elapsed":404,"user":{"displayName":"KARTHIK B (RA2112701010014)","userId":"06219581223758280302"}},"outputId":"4717e8f4-eff3-42d9-8db0-e592123beb0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-100. -101. -102. -103.]\n"," [-101. -198. -199. -100.]\n"," [-100. -199. -200. -100.]\n"," [-199. -200. -201. -100.]]\n"]}]}]}